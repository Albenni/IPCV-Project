{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d41535fd",
      "metadata": {
        "id": "d41535fd"
      },
      "source": [
        "# Assignment Module 2: Pet Classification\n",
        "\n",
        "The goal of this assignment is to implement a neural network that classifies images of 37 breeds of cats and dogs from the [Oxford-IIIT-Pet dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The assignment is divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1476550",
      "metadata": {
        "id": "b1476550"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The following cells contain the code to download and access the dataset you will be using in this assignment. Note that, although this dataset features each and every image from [Oxford-IIIT-Pet](https://www.robots.ox.ac.uk/~vgg/data/pets/), it uses a different train-val-test split than the original authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91101a0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91101a0d",
        "outputId": "f6223f14-e121-4053-b438-56bf5cd94974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ipcv-assignment-2'...\n",
            "remote: Enumerating objects: 7371, done.\u001b[K\n",
            "remote: Total 7371 (delta 0), reused 0 (delta 0), pack-reused 7371 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7371/7371), 753.77 MiB | 24.18 MiB/s, done.\n",
            "Updating files: 100% (7396/7396), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CVLAB-Unibo/ipcv-assignment-2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8fb0d2",
      "metadata": {
        "id": "0d8fb0d2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99c9929",
      "metadata": {
        "id": "b99c9929"
      },
      "outputs": [],
      "source": [
        "class OxfordPetDataset(Dataset):\n",
        "    def __init__(self, split: str, transform=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = Path(\"ipcv-assignment-2\") / \"dataset\"\n",
        "        self.split = split\n",
        "        self.names, self.labels = self._get_names_and_labels()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
        "        img_path = self.root / \"images\" / f\"{self.names[idx]}.jpg\"\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def get_num_classes(self) -> int:\n",
        "        return max(self.labels) + 1\n",
        "\n",
        "    def _get_names_and_labels(self) -> Tuple[List[str], List[int]]:\n",
        "        names = []\n",
        "        labels = []\n",
        "\n",
        "        with open(self.root / \"annotations\" / f\"{self.split}.txt\") as f:\n",
        "            for line in f:\n",
        "                name, label = line.replace(\"\\n\", \"\").split(\" \")\n",
        "                names.append(name),\n",
        "                labels.append(int(label) - 1)\n",
        "\n",
        "        return names, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e655bd",
      "metadata": {
        "id": "b4e655bd"
      },
      "source": [
        "## Part 1: design your own network\n",
        "\n",
        "Your goal is to implement a convolutional neural network for image classification and train it from scratch on `OxfordPetDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~60%. You are free to achieve this however you want, except for a few rules you must follow:\n",
        "\n",
        "- Compile this notebook by displaying the results obtained by the best model you found throughout your experimentation; then show how, by removing some of its components, its performance drops. In other words, do an *ablation study* to prove that your design choices have a positive impact on the final result.\n",
        "\n",
        "- Do not instantiate an off-the-self PyTorch network. Instead, construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you cannot use e.g. `torchvision.models.alexnet`.\n",
        "\n",
        "- Show your results and ablations with plots, tables, images, etc. â€” the clearer, the better.\n",
        "\n",
        "Don't be too concerned with your model performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded more points than a poorly experimentally validated model with higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QJeXV-20UL0p",
      "metadata": {
        "id": "QJeXV-20UL0p"
      },
      "source": [
        "#### Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qzKPzNFmBDIV",
      "metadata": {
        "id": "qzKPzNFmBDIV"
      },
      "outputs": [],
      "source": [
        "# 0. Imports\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78_xqXh5BDt3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78_xqXh5BDt3",
        "outputId": "7f42f509-172c-4cd7-d499-01d4da8611f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# mean / std computed on a 1-epoch pass over the training set\n",
        "MEAN = [0.4866, 0.4568, 0.4103]\n",
        "STD  = [0.2521, 0.2465, 0.2718]\n",
        "\n",
        "augmented = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "plain = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "train_ds = OxfordPetDataset('train', transform=augmented)\n",
        "val_ds   = OxfordPetDataset('val',   transform=plain)\n",
        "test_ds  = OxfordPetDataset('test',  transform=plain)\n",
        "\n",
        "train_loader = DataLoader(train_ds, 64, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "NUM_CLASSES = train_ds.get_num_classes()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gpycYrkLBPCI",
      "metadata": {
        "id": "gpycYrkLBPCI"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Identity() if in_ch==out_ch and stride==1 else \\\n",
        "                    nn.Conv2d(in_ch, out_ch, 1, stride, bias=False)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch)\n",
        "        )\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.act(self.net(x) + self.proj(x))\n",
        "\n",
        "class MiniXResNet(nn.Module):\n",
        "    def __init__(self, n_classes=37, drop=0.2):\n",
        "        super().__init__()\n",
        "        # stem (depth-wise separable)\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),          # groups default to 1\n",
        "            nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, 2, 1),\n",
        "            nn.Conv2d(32, 64, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "        )\n",
        "        # stages\n",
        "        self.stage1 = BasicBlock(64, 128, 2)\n",
        "        self.stage2 = BasicBlock(128, 256, 2)\n",
        "        self.stage3 = nn.Sequential(\n",
        "            BasicBlock(256, 256),\n",
        "            BasicBlock(256, 512, 2)\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLnULFUrBW1U",
      "metadata": {
        "id": "qLnULFUrBW1U"
      },
      "outputs": [],
      "source": [
        "def accuracy(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n",
        "\n",
        "def run_epoch(model, loader, opt=None):\n",
        "    train = opt is not None\n",
        "    model.train(train)\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        if train:\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "        total_loss += loss.item()*x.size(0)\n",
        "        total_acc  += accuracy(logits, y)*x.size(0)\n",
        "    n = len(loader.dataset)\n",
        "    return total_loss/n, total_acc/n\n",
        "\n",
        "def fit(model, epochs=15, lr=3e-4):\n",
        "    model.cuda()\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr, weight_decay=1e-4)\n",
        "    best_val, best_state = 0, None\n",
        "    for ep in range(1,epochs+1):\n",
        "        tr_loss, tr_acc = run_epoch(model, train_loader, opt)\n",
        "        val_loss, val_acc = run_epoch(model, val_loader)\n",
        "        if val_acc > best_val:\n",
        "            best_val, best_state = val_acc, model.state_dict()\n",
        "        print(f\"ep {ep:02d}: train {tr_acc*100:5.1f} | val {val_acc*100:5.1f}\")\n",
        "    model.load_state_dict(best_state)\n",
        "    tst_loss, tst_acc = run_epoch(model, test_loader)\n",
        "    print(f\"\\nTEST ACCURACY: {tst_acc*100:5.1f} %\")\n",
        "    return best_val, tst_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wR8WLV5lUPgC",
      "metadata": {
        "id": "wR8WLV5lUPgC"
      },
      "source": [
        "#### Ablation study\n",
        "- Variant A: no data augmentation\n",
        "\n",
        "- Variant B: no BatchNorm + Dropout\n",
        "\n",
        "- Variant C: shallow network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OQ40G1sLUR4u",
      "metadata": {
        "id": "OQ40G1sLUR4u"
      },
      "outputs": [],
      "source": [
        "# Variant A\n",
        "train_ds.transform = plain\n",
        "\n",
        "# Variant B\n",
        "class MiniXResNetNoBN(MiniXResNet):\n",
        "    def __init__(self,n_classes=37):\n",
        "        super().__init__(n_classes, drop=0.)\n",
        "        self.apply(self.remove_bn)\n",
        "    def remove_bn(self,m):\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            return nn.Identity()\n",
        "        return m\n",
        "\n",
        "# Variant C\n",
        "class MiniXResNetShallow(MiniXResNet):\n",
        "    def __init__(self,n_classes=37, drop=0.2):\n",
        "        super().__init__(n_classes,drop)\n",
        "        self.stage3 = nn.Identity()\n",
        "        self.head[2] = nn.Linear(256, n_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ywAqf14HUhUp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywAqf14HUhUp",
        "outputId": "d372916a-743b-4814-9c65-56e1346084d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Baseline ====\n",
            "ep 01: train   6.6 | val   8.7\n",
            "ep 02: train  10.5 | val   9.9\n",
            "ep 03: train  14.3 | val  13.2\n",
            "ep 04: train  17.9 | val  16.6\n",
            "ep 05: train  21.5 | val  17.1\n",
            "ep 06: train  24.6 | val  16.8\n",
            "ep 07: train  26.9 | val  20.9\n",
            "ep 08: train  28.6 | val  21.9\n",
            "ep 09: train  32.1 | val  22.8\n",
            "ep 10: train  34.8 | val  24.6\n",
            "ep 11: train  37.5 | val  26.5\n",
            "ep 12: train  39.6 | val  23.8\n",
            "ep 13: train  43.4 | val  30.4\n",
            "ep 14: train  45.5 | val  33.5\n",
            "ep 15: train  48.4 | val  32.2\n",
            "\n",
            "TEST ACCURACY:  37.6 %\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "print(\"\\n==== Baseline ====\")\n",
        "train_ds.transform = augmented\n",
        "baseline = fit(MiniXResNet())\n",
        "results[\"Baseline\"] = baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eIpJ8eyY8sm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eIpJ8eyY8sm",
        "outputId": "79690f66-84c6-42be-a47f-ef85e49b7c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Variant A (no augm) ====\n",
            "ep 01: train   9.6 | val   9.7\n",
            "ep 02: train  18.0 | val  16.8\n",
            "ep 03: train  22.3 | val  16.2\n",
            "ep 04: train  27.6 | val  20.4\n",
            "ep 05: train  33.1 | val  15.3\n",
            "ep 06: train  38.4 | val  24.1\n",
            "ep 07: train  42.0 | val  21.0\n",
            "ep 08: train  48.1 | val  24.3\n",
            "ep 09: train  52.0 | val  29.8\n",
            "ep 10: train  57.2 | val  29.5\n",
            "ep 11: train  65.2 | val  30.5\n",
            "ep 12: train  72.8 | val  29.0\n",
            "ep 13: train  76.0 | val  30.5\n",
            "ep 14: train  82.3 | val  22.0\n",
            "ep 15: train  83.3 | val  28.1\n",
            "\n",
            "TEST ACCURACY:  29.0 %\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==== Variant A (no augm) ====\")\n",
        "train_ds.transform = plain\n",
        "var_a = fit(MiniXResNet())\n",
        "results[\"No Augmentation\"] = var_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "if1gZVEoY9-o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if1gZVEoY9-o",
        "outputId": "061bb25d-636c-4883-cf5a-031ee25db1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Variant B (no BN / no Dropout) ====\n",
            "ep 01: train   7.7 | val   9.8\n",
            "ep 02: train  11.1 | val  11.0\n",
            "ep 03: train  16.4 | val  14.8\n",
            "ep 04: train  19.7 | val  16.2\n",
            "ep 05: train  22.2 | val  18.2\n",
            "ep 06: train  26.6 | val  20.3\n",
            "ep 07: train  29.3 | val  15.8\n",
            "ep 08: train  33.2 | val  25.9\n",
            "ep 09: train  34.2 | val  20.1\n",
            "ep 10: train  37.6 | val  25.1\n",
            "ep 11: train  40.0 | val  24.2\n",
            "ep 12: train  45.4 | val  24.0\n",
            "ep 13: train  44.9 | val  26.1\n",
            "ep 14: train  50.4 | val  31.5\n",
            "ep 15: train  54.0 | val  31.7\n",
            "\n",
            "TEST ACCURACY:  34.8 %\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==== Variant B (no BN / no Dropout) ====\")\n",
        "train_ds.transform = augmented\n",
        "var_b = fit(MiniXResNetNoBN())\n",
        "results[\"No BN/Dropout\"] = var_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YEA3VfXwZAho",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEA3VfXwZAho",
        "outputId": "72c998f6-3656-4a4b-fff6-d55f91fb1c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Variant C (shallow) ====\n",
            "ep 01: train   6.6 | val   8.5\n",
            "ep 02: train  10.2 | val  10.7\n",
            "ep 03: train  11.9 | val  13.6\n",
            "ep 04: train  14.0 | val  12.9\n",
            "ep 05: train  16.1 | val  15.5\n",
            "ep 06: train  18.7 | val  15.8\n",
            "ep 07: train  20.3 | val  17.9\n",
            "ep 08: train  21.6 | val  17.2\n",
            "ep 09: train  24.2 | val  18.6\n",
            "ep 10: train  25.2 | val  21.7\n",
            "ep 11: train  26.4 | val  20.9\n",
            "ep 12: train  29.2 | val  19.9\n",
            "ep 13: train  29.2 | val  24.6\n",
            "ep 14: train  30.7 | val  24.3\n",
            "ep 15: train  32.5 | val  19.5\n",
            "\n",
            "TEST ACCURACY:  21.5 %\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n==== Variant C (shallow) ====\")\n",
        "var_c = fit(MiniXResNetShallow())\n",
        "results[\"Shallow\"] = var_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90pJ7H-OU1s1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "90pJ7H-OU1s1",
        "outputId": "c89bb4a2-fddb-4504-8f77-cecc8616d882"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "accuracies = [np.mean(v)*100 for v in results.values()]  # Convert to percentages\n",
        "bars = plt.bar(results.keys(), accuracies, color=\"steelblue\")\n",
        "plt.ylabel(\"Test Accuracy (%)\")\n",
        "plt.title(\"Ablation Study on Oxford-IIIT-Pet\")\n",
        "\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f\"{bar.get_height():.1f}%\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
        "\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ACtvMdq0nh__",
      "metadata": {
        "id": "ACtvMdq0nh__"
      },
      "source": [
        "We can se how different features of our architecture improve accuracy. Let's try to improve it even more:\n",
        "\n",
        "- From 15 to 30 epochs\n",
        "- From fixed learning rate to cosine decay\n",
        "- Increase augmentation\n",
        "- More depth in stage 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sHOeXjH0nta-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHOeXjH0nta-",
        "outputId": "5c281ad8-f2e3-4ef0-ff88-b1c3de8cb9e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.4866, 0.4568, 0.4103]\n",
        "STD  = [0.2521, 0.2465, 0.2718]\n",
        "\n",
        "augmented = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # PUNTO 4: Random Perspective\n",
        "    transforms.RandomRotation(degrees=15),                     # PUNTO 4: Rotazione casuale\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "plain = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "train_ds = OxfordPetDataset('train', augmented)\n",
        "val_ds   = OxfordPetDataset('val', plain)\n",
        "test_ds  = OxfordPetDataset('test', plain)\n",
        "\n",
        "train_loader = DataLoader(train_ds, 64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "NUM_CLASSES = train_ds.get_num_classes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-gg7y30mFYDV",
      "metadata": {
        "id": "-gg7y30mFYDV"
      },
      "outputs": [],
      "source": [
        "class MiniXResNet_v2(nn.Module):\n",
        "    def __init__(self, n_classes=37, drop=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # STEM: con gruppi depthwise separable\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 3, 3, 2, 1, bias=False, groups=3),   # depthwise 3â†’3\n",
        "            nn.Conv2d(3, 32, 1, 1, 0, bias=False),            # pointwise 3â†’32\n",
        "            nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3,2,1),\n",
        "            nn.Conv2d(32, 64, 1, 1, 0, bias=False),           # aumenta a 64\n",
        "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.stage1 = BasicBlock(64, 128, 2)\n",
        "\n",
        "        self.stage2 = BasicBlock(128, 256, 2)\n",
        "\n",
        "        self.stage3 = nn.Sequential(\n",
        "            BasicBlock(256, 512, 2),\n",
        "            BasicBlock(512, 512)\n",
        "        )\n",
        "\n",
        "        # POOLING + CLASSIFICATORE\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(512, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fMTAoMGokok",
      "metadata": {
        "id": "1fMTAoMGokok"
      },
      "outputs": [],
      "source": [
        "def run_epoch_v2(model, loader, opt=None):\n",
        "    model.train(opt is not None)\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.cuda(), y.cuda()\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        if opt:\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_acc += (logits.argmax(1) == y).float().sum().item()\n",
        "    return total_loss/len(loader.dataset), total_acc/len(loader.dataset)\n",
        "\n",
        "\n",
        "def fit_v2(model, epochs=30, lr=3e-4):\n",
        "    model.cuda()\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    # add cosine annealing LR scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    best_val, best_state = 0, None\n",
        "    history = {'train_acc':[], 'val_acc':[]}\n",
        "    for ep in range(1, epochs+1):\n",
        "        _, train_acc = run_epoch_v2(model, train_loader, opt)\n",
        "        _, val_acc   = run_epoch_v2(model, val_loader)\n",
        "        scheduler.step()  # aggiorno lr secondo cosine\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        if val_acc > best_val:\n",
        "            best_val, best_state = val_acc, model.state_dict()\n",
        "        print(f\"Ep{ep:02d} âˆ’ train {train_acc*100:.1f}% | val {val_acc*100:.1f}% | lr={opt.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    _, test_acc = run_epoch_v2(model, test_loader)\n",
        "    print(f\"\\nâ†’ TEST ACCURACY finale: {test_acc*100:.1f}%\")\n",
        "    return history, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j4Fx_-D_pKmw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Fx_-D_pKmw",
        "outputId": "0d37457a-3e65-431c-e18b-9a1fe4c2259c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep01 âˆ’ train 6.6% | val 7.3% | lr=2.99e-04\n",
            "Ep02 âˆ’ train 9.6% | val 10.7% | lr=2.97e-04\n",
            "Ep03 âˆ’ train 12.2% | val 11.3% | lr=2.93e-04\n",
            "Ep04 âˆ’ train 15.3% | val 10.5% | lr=2.87e-04\n",
            "Ep05 âˆ’ train 17.7% | val 14.1% | lr=2.80e-04\n",
            "Ep06 âˆ’ train 20.1% | val 14.3% | lr=2.71e-04\n",
            "Ep07 âˆ’ train 24.2% | val 15.3% | lr=2.62e-04\n",
            "Ep08 âˆ’ train 24.9% | val 15.6% | lr=2.51e-04\n",
            "Ep09 âˆ’ train 28.7% | val 20.8% | lr=2.38e-04\n",
            "Ep10 âˆ’ train 30.6% | val 23.1% | lr=2.25e-04\n",
            "Ep11 âˆ’ train 32.9% | val 23.8% | lr=2.11e-04\n",
            "Ep12 âˆ’ train 37.4% | val 26.0% | lr=1.97e-04\n",
            "Ep13 âˆ’ train 39.9% | val 27.9% | lr=1.82e-04\n",
            "Ep14 âˆ’ train 40.7% | val 28.5% | lr=1.66e-04\n",
            "Ep15 âˆ’ train 44.6% | val 31.7% | lr=1.50e-04\n",
            "Ep16 âˆ’ train 47.2% | val 32.8% | lr=1.35e-04\n",
            "Ep17 âˆ’ train 51.0% | val 33.6% | lr=1.19e-04\n",
            "Ep18 âˆ’ train 53.9% | val 31.0% | lr=1.04e-04\n",
            "Ep19 âˆ’ train 56.1% | val 35.1% | lr=8.97e-05\n",
            "Ep20 âˆ’ train 57.9% | val 38.1% | lr=7.58e-05\n",
            "Ep21 âˆ’ train 60.0% | val 36.6% | lr=6.26e-05\n",
            "Ep22 âˆ’ train 64.6% | val 40.0% | lr=5.05e-05\n",
            "Ep23 âˆ’ train 65.6% | val 39.9% | lr=3.94e-05\n",
            "Ep24 âˆ’ train 66.1% | val 40.3% | lr=2.96e-05\n",
            "Ep25 âˆ’ train 69.3% | val 42.9% | lr=2.10e-05\n",
            "Ep26 âˆ’ train 72.6% | val 42.3% | lr=1.39e-05\n",
            "Ep27 âˆ’ train 71.4% | val 43.2% | lr=8.32e-06\n",
            "Ep28 âˆ’ train 73.4% | val 43.0% | lr=4.27e-06\n",
            "Ep29 âˆ’ train 75.0% | val 43.4% | lr=1.82e-06\n",
            "Ep30 âˆ’ train 73.1% | val 43.7% | lr=1.00e-06\n",
            "\n",
            "â†’ TEST ACCURACY finale: 45.7%\n"
          ]
        }
      ],
      "source": [
        "model = MiniXResNet_v2(n_classes=NUM_CLASSES, drop=0.2)\n",
        "history, test_acc = fit_v2(model, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48U8hw9MM3eA",
      "metadata": {
        "id": "48U8hw9MM3eA"
      },
      "source": [
        "We can notice great improvement with the last changes, but:\n",
        "- Increasing train/validation gap (train 73%, val 43%)\n",
        "- Validation accuracy plateau after the 22nd epoch\n",
        "\n",
        "Therefore, this is a classic case of overfitting.\n",
        "\n",
        "Let's try some adjustments:\n",
        "- dropout from 0.2 to 0.4\n",
        "- increase augmentation: *transforms.RandomErasing(p=0.2, scale=(0.02, 0.2))*\n",
        "- t_max and epochs to 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K8kD9Gb2PCls",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8kD9Gb2PCls",
        "outputId": "300e5cad-246a-42da-b605-0eed69d71603"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.4866, 0.4568, 0.4103]\n",
        "STD  = [0.2521, 0.2465, 0.2718]\n",
        "\n",
        "augmented = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2))\n",
        "])\n",
        "\n",
        "plain = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "train_ds = OxfordPetDataset('train', augmented)\n",
        "val_ds   = OxfordPetDataset('val', plain)\n",
        "test_ds  = OxfordPetDataset('test', plain)\n",
        "\n",
        "train_loader = DataLoader(train_ds, 64, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader   = DataLoader(val_ds,   64, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "test_loader  = DataLoader(test_ds,  64, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "NUM_CLASSES = train_ds.get_num_classes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5HAMefQCOvBG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HAMefQCOvBG",
        "outputId": "53539c27-cd15-423e-f847-3ea230cbf49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep01 âˆ’ train 6.4% | val 8.8% | lr=3.00e-04\n",
            "Ep02 âˆ’ train 8.9% | val 11.6% | lr=2.99e-04\n",
            "Ep03 âˆ’ train 12.7% | val 10.0% | lr=2.97e-04\n",
            "Ep04 âˆ’ train 14.2% | val 13.8% | lr=2.95e-04\n",
            "Ep05 âˆ’ train 16.2% | val 12.9% | lr=2.93e-04\n",
            "Ep06 âˆ’ train 19.4% | val 15.4% | lr=2.90e-04\n",
            "Ep07 âˆ’ train 21.0% | val 19.9% | lr=2.86e-04\n",
            "Ep08 âˆ’ train 24.0% | val 18.3% | lr=2.82e-04\n",
            "Ep09 âˆ’ train 27.1% | val 21.6% | lr=2.77e-04\n",
            "Ep10 âˆ’ train 28.9% | val 23.7% | lr=2.71e-04\n",
            "Ep11 âˆ’ train 32.1% | val 26.8% | lr=2.66e-04\n",
            "Ep12 âˆ’ train 34.6% | val 24.5% | lr=2.59e-04\n",
            "Ep13 âˆ’ train 36.2% | val 30.0% | lr=2.53e-04\n",
            "Ep14 âˆ’ train 39.5% | val 30.0% | lr=2.46e-04\n",
            "Ep15 âˆ’ train 41.0% | val 29.0% | lr=2.38e-04\n",
            "Ep16 âˆ’ train 43.2% | val 33.2% | lr=2.31e-04\n",
            "Ep17 âˆ’ train 47.0% | val 33.0% | lr=2.23e-04\n",
            "Ep18 âˆ’ train 48.4% | val 35.8% | lr=2.14e-04\n",
            "Ep19 âˆ’ train 50.3% | val 34.9% | lr=2.06e-04\n",
            "Ep20 âˆ’ train 52.0% | val 35.2% | lr=1.97e-04\n",
            "Ep21 âˆ’ train 54.8% | val 33.6% | lr=1.88e-04\n",
            "Ep22 âˆ’ train 58.5% | val 39.3% | lr=1.79e-04\n",
            "Ep23 âˆ’ train 59.1% | val 35.6% | lr=1.69e-04\n",
            "Ep24 âˆ’ train 61.3% | val 38.1% | lr=1.60e-04\n",
            "Ep25 âˆ’ train 62.4% | val 37.6% | lr=1.50e-04\n",
            "Ep26 âˆ’ train 65.3% | val 37.9% | lr=1.41e-04\n",
            "Ep27 âˆ’ train 67.1% | val 44.0% | lr=1.32e-04\n",
            "Ep28 âˆ’ train 69.1% | val 43.3% | lr=1.22e-04\n",
            "Ep29 âˆ’ train 69.5% | val 44.0% | lr=1.13e-04\n",
            "Ep30 âˆ’ train 73.4% | val 43.1% | lr=1.04e-04\n",
            "Ep31 âˆ’ train 75.0% | val 42.6% | lr=9.55e-05\n",
            "Ep32 âˆ’ train 76.2% | val 46.4% | lr=8.68e-05\n",
            "Ep33 âˆ’ train 78.9% | val 47.2% | lr=7.85e-05\n",
            "Ep34 âˆ’ train 80.0% | val 46.9% | lr=7.04e-05\n",
            "Ep35 âˆ’ train 81.1% | val 48.2% | lr=6.26e-05\n",
            "Ep36 âˆ’ train 81.8% | val 49.0% | lr=5.52e-05\n",
            "Ep37 âˆ’ train 83.2% | val 49.1% | lr=4.82e-05\n",
            "Ep38 âˆ’ train 84.5% | val 49.1% | lr=4.15e-05\n",
            "Ep39 âˆ’ train 86.2% | val 49.7% | lr=3.53e-05\n",
            "Ep40 âˆ’ train 85.7% | val 51.2% | lr=2.96e-05\n",
            "Ep41 âˆ’ train 87.2% | val 49.6% | lr=2.43e-05\n",
            "Ep42 âˆ’ train 89.0% | val 49.8% | lr=1.95e-05\n",
            "Ep43 âˆ’ train 89.0% | val 49.7% | lr=1.52e-05\n",
            "Ep44 âˆ’ train 88.6% | val 50.1% | lr=1.15e-05\n",
            "Ep45 âˆ’ train 89.6% | val 50.3% | lr=8.32e-06\n",
            "Ep46 âˆ’ train 89.9% | val 50.5% | lr=5.70e-06\n",
            "Ep47 âˆ’ train 89.9% | val 50.2% | lr=3.65e-06\n",
            "Ep48 âˆ’ train 90.5% | val 50.2% | lr=2.18e-06\n",
            "Ep49 âˆ’ train 90.4% | val 50.1% | lr=1.30e-06\n",
            "Ep50 âˆ’ train 89.6% | val 49.9% | lr=1.00e-06\n",
            "\n",
            "â†’ TEST ACCURACY finale: 55.0%\n"
          ]
        }
      ],
      "source": [
        "model = MiniXResNet_v2(n_classes=NUM_CLASSES, drop=0.4)\n",
        "history, test_acc = fit_v2(model, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I3761GUfZlaR",
      "metadata": {
        "id": "I3761GUfZlaR"
      },
      "source": [
        "We still have overfitting but accuracy is improved\n",
        "\n",
        "#### Let's try with complete different architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cGO4u0T8ZkpM",
      "metadata": {
        "id": "cGO4u0T8ZkpM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# 1. Squeeze-and-Excitation (SE Block)\n",
        "# --------------------------------------------------------\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_ch, r=4):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_ch, in_ch // r),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_ch // r, in_ch),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        b,c,_,_ = x.size()\n",
        "        s = self.pool(x).view(b,c)\n",
        "        s = self.fc(s).view(b,c,1,1)\n",
        "        return x * s\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# 2. MBConv block (Mobile Inverted Bottleneck + SE)\n",
        "# --------------------------------------------------------\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1, expand=6):\n",
        "        super().__init__()\n",
        "        mid_ch = in_ch * expand\n",
        "        self.use_residual = (in_ch == out_ch and stride == 1)\n",
        "\n",
        "        self.expand = nn.Conv2d(in_ch, mid_ch, 1, 1, 0, bias=False)\n",
        "        self.expand_bn = nn.BatchNorm2d(mid_ch)\n",
        "\n",
        "        self.depthwise = nn.Conv2d(mid_ch, mid_ch, 3, stride, 1, groups=mid_ch, bias=False)\n",
        "        self.depthwise_bn = nn.BatchNorm2d(mid_ch)\n",
        "\n",
        "        self.se = SEBlock(mid_ch)\n",
        "\n",
        "        self.project = nn.Conv2d(mid_ch, out_ch, 1, 1, 0, bias=False)\n",
        "        self.project_bn = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "        self.act = nn.SiLU(inplace=True)  # Swish-like activation\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.act(self.expand_bn(self.expand(x)))\n",
        "        out = self.act(self.depthwise_bn(self.depthwise(out)))\n",
        "        out = self.se(out)\n",
        "        out = self.project_bn(self.project(out))\n",
        "        if self.use_residual:\n",
        "            return out + x\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# 3. EfficientNet-Mini architecture\n",
        "# --------------------------------------------------------\n",
        "\n",
        "class EfficientNetMini(nn.Module):\n",
        "    def __init__(self, num_classes=37, drop=0.3):\n",
        "        super().__init__()\n",
        "        # Stem\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.SiLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Stages\n",
        "        self.stage1 = nn.Sequential(\n",
        "            MBConv(32, 16, stride=1, expand=1),\n",
        "        )\n",
        "        self.stage2 = nn.Sequential(\n",
        "            MBConv(16, 24, stride=2, expand=6),\n",
        "            MBConv(24, 24, stride=1, expand=6),\n",
        "        )\n",
        "        self.stage3 = nn.Sequential(\n",
        "            MBConv(24, 40, stride=2, expand=6),\n",
        "            MBConv(40, 40, stride=1, expand=6),\n",
        "        )\n",
        "        self.stage4 = nn.Sequential(\n",
        "            MBConv(40, 80, stride=2, expand=6),\n",
        "            MBConv(80, 80, stride=1, expand=6),\n",
        "        )\n",
        "        self.stage5 = nn.Sequential(\n",
        "            MBConv(80, 112, stride=1, expand=6),\n",
        "            MBConv(112, 112, stride=1, expand=6),\n",
        "        )\n",
        "        self.stage6 = nn.Sequential(\n",
        "            MBConv(112, 192, stride=2, expand=6),\n",
        "            MBConv(192, 192, stride=1, expand=6),\n",
        "        )\n",
        "\n",
        "        # Head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(192, 320, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(320, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.stage5(x)\n",
        "        x = self.stage6(x)\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2iPrUOZj3_",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef2iPrUOZj3_",
        "outputId": "fd918b11-ef42-4424-c8e0-0b7ce5fc1310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep01 âˆ’ train 4.7% | val 5.0% | lr=9.99e-04\n",
            "Ep02 âˆ’ train 9.0% | val 9.0% | lr=9.96e-04\n",
            "Ep03 âˆ’ train 10.3% | val 9.9% | lr=9.91e-04\n",
            "Ep04 âˆ’ train 14.3% | val 12.5% | lr=9.84e-04\n",
            "Ep05 âˆ’ train 15.6% | val 12.8% | lr=9.76e-04\n",
            "Ep06 âˆ’ train 18.8% | val 16.4% | lr=9.65e-04\n",
            "Ep07 âˆ’ train 23.2% | val 21.9% | lr=9.52e-04\n",
            "Ep08 âˆ’ train 24.7% | val 22.8% | lr=9.38e-04\n",
            "Ep09 âˆ’ train 28.6% | val 26.1% | lr=9.22e-04\n",
            "Ep10 âˆ’ train 30.9% | val 22.6% | lr=9.05e-04\n",
            "Ep11 âˆ’ train 34.0% | val 28.8% | lr=8.85e-04\n",
            "Ep12 âˆ’ train 37.6% | val 30.6% | lr=8.65e-04\n",
            "Ep13 âˆ’ train 39.6% | val 34.6% | lr=8.42e-04\n",
            "Ep14 âˆ’ train 40.8% | val 31.9% | lr=8.19e-04\n",
            "Ep15 âˆ’ train 45.7% | val 37.4% | lr=7.94e-04\n",
            "Ep16 âˆ’ train 49.4% | val 37.0% | lr=7.68e-04\n",
            "Ep17 âˆ’ train 51.6% | val 42.1% | lr=7.41e-04\n",
            "Ep18 âˆ’ train 52.9% | val 41.7% | lr=7.13e-04\n",
            "Ep19 âˆ’ train 55.5% | val 46.3% | lr=6.84e-04\n",
            "Ep20 âˆ’ train 57.3% | val 44.4% | lr=6.55e-04\n",
            "Ep21 âˆ’ train 58.9% | val 47.2% | lr=6.25e-04\n",
            "Ep22 âˆ’ train 59.9% | val 47.5% | lr=5.94e-04\n",
            "Ep23 âˆ’ train 64.0% | val 46.9% | lr=5.63e-04\n",
            "Ep24 âˆ’ train 64.6% | val 51.7% | lr=5.32e-04\n",
            "Ep25 âˆ’ train 67.0% | val 49.3% | lr=5.00e-04\n",
            "Ep26 âˆ’ train 67.7% | val 52.7% | lr=4.69e-04\n",
            "Ep27 âˆ’ train 69.4% | val 52.9% | lr=4.38e-04\n",
            "Ep28 âˆ’ train 69.9% | val 52.8% | lr=4.07e-04\n",
            "Ep29 âˆ’ train 73.3% | val 53.3% | lr=3.76e-04\n",
            "Ep30 âˆ’ train 72.6% | val 55.6% | lr=3.46e-04\n",
            "Ep31 âˆ’ train 74.1% | val 53.3% | lr=3.17e-04\n",
            "Ep32 âˆ’ train 76.1% | val 55.8% | lr=2.88e-04\n",
            "Ep33 âˆ’ train 76.0% | val 56.7% | lr=2.60e-04\n",
            "Ep34 âˆ’ train 77.0% | val 57.1% | lr=2.33e-04\n",
            "Ep35 âˆ’ train 78.4% | val 56.4% | lr=2.07e-04\n",
            "Ep36 âˆ’ train 80.2% | val 57.4% | lr=1.82e-04\n",
            "Ep37 âˆ’ train 80.8% | val 57.9% | lr=1.59e-04\n",
            "Ep38 âˆ’ train 81.4% | val 59.5% | lr=1.36e-04\n",
            "Ep39 âˆ’ train 81.7% | val 58.9% | lr=1.16e-04\n",
            "Ep40 âˆ’ train 83.0% | val 60.2% | lr=9.64e-05\n",
            "Ep41 âˆ’ train 82.7% | val 59.4% | lr=7.88e-05\n",
            "Ep42 âˆ’ train 83.4% | val 59.4% | lr=6.28e-05\n",
            "Ep43 âˆ’ train 84.4% | val 60.4% | lr=4.85e-05\n",
            "Ep44 âˆ’ train 85.0% | val 60.6% | lr=3.61e-05\n",
            "Ep45 âˆ’ train 84.8% | val 60.5% | lr=2.54e-05\n",
            "Ep46 âˆ’ train 85.6% | val 60.6% | lr=1.67e-05\n",
            "Ep47 âˆ’ train 85.0% | val 60.7% | lr=9.85e-06\n",
            "Ep48 âˆ’ train 86.0% | val 61.1% | lr=4.94e-06\n",
            "Ep49 âˆ’ train 85.6% | val 60.5% | lr=1.99e-06\n",
            "Ep50 âˆ’ train 85.6% | val 61.5% | lr=1.00e-06\n",
            "\n",
            "â†’ TEST ACCURACY finale: 64.3%\n"
          ]
        }
      ],
      "source": [
        "model = EfficientNetMini(num_classes=NUM_CLASSES, drop=0.3)\n",
        "history, test_acc = fit_v2(model, epochs=50, lr=1e-3) #fit_v2(model, epochs=40)  45% accur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N0TyfSLP2bzc",
      "metadata": {
        "id": "N0TyfSLP2bzc"
      },
      "source": [
        "With this architecture we managed to reduce overfitting, improving accuracy.\n",
        "Probably 40 epochs are enough."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192fb2ce",
      "metadata": {
        "id": "192fb2ce"
      },
      "source": [
        "## Part 2: fine-tune an existing network\n",
        "\n",
        "Your goal is to fine-tune a pretrained ResNet-18 model on `OxfordPetDataset`. Use the implementation provided by PyTorch, i.e. the opposite of part 1. Specifically, use the PyTorch ResNet-18 model pretrained on ImageNet-1K (V1). Divide your fine-tuning into two parts:\n",
        "\n",
        "2A. First, fine-tune the ResNet-18 with the same training hyperparameters you used for your best model in part 1.\n",
        "\n",
        "2B. Then, tweak the training hyperparameters in order to increase the accuracy on the test split. Justify your choices by analyzing the training plots and/or citing sources that guided you in your decisions â€” papers, blog posts, YouTube videos, or whatever else you may find useful. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~90%."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}